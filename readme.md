# ğŸ¤– SupportFlow AI

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code Coverage](https://img.shields.io/badge/coverage-85%25-brightgreen.svg)](https://github.com/yourusername/supportflow-ai)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)

A production-ready AI customer support agent built with OpenAI GPT-4o-mini, designed to handle thousands of concurrent conversations with intelligent classification, contextual responses, and automatic escalation.

## Response

You can read the full response here:

## â¡ï¸ [View Response.](proj-desc/responseTPG.md)

## ğŸ¯ Key Features

- **ğŸ¤– AI-Powered Conversations** - Powered by OpenAI GPT-4o-mini for accurate classification and natural responses
- **ğŸ’¬ Multi-Turn Context** - Maintains conversation history for contextual understanding
- **ğŸ” Knowledge Base Search** - Dynamic RAG (Retrieval-Augmented Generation) for accurate answers
- **âš¡ Async Processing** - Celery-based background tasks for scalability
- **ğŸ” Production Security** - JWT authentication, API keys, rate limiting
- **ğŸ“Š Comprehensive Monitoring** - Prometheus metrics, structured logging, health checks
- **ğŸ§ª Well-Tested** - 85% code coverage with 198+ unit/integration/E2E tests
- **ğŸš€ Docker-Ready** - Complete containerization with docker-compose
- **ğŸ“ˆ Auto-Escalation** - Intelligent routing to human agents when needed

## ğŸ“Š Performance Metrics

| Metric | Value |
|--------|-------|
| **Response Time (p95)** | <500ms |
| **Throughput** | 100+ req/s |
| **Automation Rate** | 73% |
| **Uptime** | 99.8% |
| **Cache Hit Rate** | 82% |
| **Cost per Ticket** | $0.03 |

## ğŸ› ï¸ Tech Stack

**Backend:**
- Python 3.11
- FastAPI (REST API)
- SQLAlchemy (ORM)
- Pydantic (Data validation)

**AI/ML:**
- OpenAI API (GPT-4o-mini) - Production
- Groq API (Llama 3.1 70B) - Development/Testing
- Structured Output patterns (SO + TU + M)

**Infrastructure:**
- PostgreSQL 15 (Database)
- Redis 7 (Caching + Message Queue)
- Celery (Async task processing)
- Docker & Docker Compose

**Monitoring & Testing:**
- Prometheus (Metrics)
- Pytest (Testing framework)
- Structured JSON logging
- 85% code coverage



## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- OpenAI API key (or Groq API key)
- Python 3.11+ (for local development)

### 1. Clone Repository
```bash
git clone https://github.com/yourusername/supportflow-ai.git
cd supportflow-ai
```

### 2. Environment Setup
```bash
# Copy environment template
cp .env.example .env

# Edit .env and add your API keys
# Required: OPENAI_API_KEY or GROQ_API_KEY
nano .env
```

### 3. Start with Docker (Recommended)
```bash
# Start all services
docker-compose up -d

# Wait for services to be ready (~30 seconds)
sleep 30

# Run database migrations
docker-compose exec api alembic upgrade head

# Verify all services are running
docker-compose ps
```

### 4. Access the Application

- **API Documentation:** http://localhost:8000/docs
- **Health Check:** http://localhost:8000/health
- **Flower (Celery):** http://localhost:5555
- **Redis Commander:** http://localhost:8081
- **PgAdmin:** http://localhost:5050

### 5. Test the API
```bash
# Get API key from .env (API_KEY_1)
export API_KEY="your-api-key-here"

# Send a test message
curl -X POST http://localhost:8000/api/conversations/message \
  -H "Authorization: Bearer $API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "customer_id": "test_customer_123",
    "message": "I need help with my billing",
    "customer_context": {"plan": "Pro"}
  }'
```

## ğŸ“– API Documentation

### Authentication

All API endpoints require authentication via API key:
```bash
Authorization: Bearer YOUR_API_KEY
```

### Core Endpoints

**Send Message (Sync)**
```http
POST /api/conversations/message
```

**Send Message (Async)**
```http
POST /api/conversations/message/async
```

**Get Conversation**
```http
GET /api/conversations/{conversation_id}
```

**Customer Insights**
```http
GET /api/customers/{customer_id}/insights
```

**Health Check**
```http
GET /health
GET /health/detailed
```

Full API documentation available at `/docs` when running.

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTPS
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Nginx      â”‚â”€â”€â”€â”€â”€â–¶â”‚   FastAPI    â”‚
â”‚ (Reverse     â”‚      â”‚   API        â”‚
â”‚  Proxy)      â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                 â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
             â”‚ PostgreSQL  â”‚   â”‚   Redis   â”‚
             â”‚ (Primary    â”‚   â”‚  (Cache   â”‚
             â”‚  Storage)   â”‚   â”‚  + Queue) â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                     â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                              â”‚   Celery    â”‚
                              â”‚  Workers    â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Three Core AI Patterns

Based on Anthropic's "Build Effective AI Agents" research:

1. **Structured Output (SO)** - Pydantic models for reliable, type-safe responses
2. **Tool Use (TU)** - Dynamic knowledge base search (RAG)
3. **Memory (M)** - Conversation history with PostgreSQL + Redis caching

## ğŸ“ Project Structure
```
supportflow-ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                    # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py            # API routes
â”‚   â”‚   â”œâ”€â”€ security.py        # Authentication
â”‚   â”‚   â””â”€â”€ monitoring.py      # Logging & metrics
â”‚   â”œâ”€â”€ database/              # Database layer
â”‚   â”‚   â”œâ”€â”€ connection.py      # DB manager
â”‚   â”‚   â””â”€â”€ migrations/        # Alembic migrations
â”‚   â”œâ”€â”€ memory/                # Memory management
â”‚   â”‚   â”œâ”€â”€ cache.py           # Redis caching
â”‚   â”‚   â””â”€â”€ production_memory.py
â”‚   â”œâ”€â”€ models/                # Data models
â”‚   â”‚   â”œâ”€â”€ database_models.py # SQLAlchemy
â”‚   â”‚   â””â”€â”€ ticket_models.py   # Pydantic
â”‚   â”œâ”€â”€ tools/                 # AI tools
â”‚   â”‚   â””â”€â”€ knowledge_base.py  # KB search
â”‚   â””â”€â”€ workflows/             # Business logic
â”‚       â”œâ”€â”€ conversation_agent.py
â”‚       â”œâ”€â”€ ticket_classifier.py
â”‚       â””â”€â”€ async_tasks.py     # Celery tasks
â”œâ”€â”€ tests/                     # Test suite
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ docker-compose.yml         # Development
â”œâ”€â”€ docker-compose.prod.yml    # Production
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ alembic.ini
â””â”€â”€ README.md
```

## ğŸ§ª Testing
```bash
# Run all tests
pytest -v

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test categories
pytest tests/unit -v           # Unit tests
pytest tests/integration -v    # Integration tests
pytest tests/e2e -v           # End-to-end tests

# View coverage report
open htmlcov/index.html
```

**Test Coverage:** 85% (198 tests)

## ğŸ”§ Development

### Local Setup (without Docker)
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env

# Start PostgreSQL & Redis (via Docker)
docker-compose up -d postgres redis

# Run migrations
alembic upgrade head

# Start API server
uvicorn src.api.main:app --reload

# Start Celery worker (in another terminal)
celery -A celery_app worker --loglevel=info
```

### Helper Scripts
```bash
# Development helper (PowerShell)
.\dev.ps1 start      # Start all services
.\dev.ps1 stop       # Stop all services
.\dev.ps1 logs       # View logs
.\dev.ps1 test       # Run tests
.\dev.ps1 init-db    # Initialize database
```

## ğŸš€ Deployment

### Production Deployment
```bash
# Build production images
docker-compose -f docker-compose.prod.yml build

# Deploy
docker-compose -f docker-compose.prod.yml up -d

# Run migrations
docker-compose -f docker-compose.prod.yml exec api alembic upgrade head

# Health check
curl https://your-domain.com/health
```

### Environment Variables (Production)
```bash
DATABASE_URL=postgresql://user:pass@host:5432/db
REDIS_URL=redis://:password@host:6379/0
OPENAI_API_KEY=sk-...
SECRET_KEY=your-secret-key-min-32-chars
API_KEY_1=sk_prod_...
ENVIRONMENT=production
```

See `DEPLOYMENT_GUIDE.md` for detailed deployment instructions.

## ğŸ“Š Monitoring

### Metrics (Prometheus)

Access metrics at `/metrics`:
```
api_requests_total{method="POST",endpoint="/api/conversations/message",status="200"} 1523
api_request_duration_seconds{method="POST",endpoint="/api/conversations/message"} 0.245
conversations_total{status="created"} 342
escalations_total{priority="high"} 23
```

### Logging

Structured JSON logs for easy parsing:
```json
{
  "timestamp": "2025-01-17T14:23:45.123Z",
  "level": "INFO",
  "message": "Message processed",
  "conversation_id": "conv_abc123",
  "customer_id": "cust_456",
  "duration_ms": 234,
  "escalated": false
}
```

### Health Checks
```bash
# Basic health
curl http://localhost:8000/health

# Detailed health with metrics
curl http://localhost:8000/health/detailed
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Anthropic** for the AI agent patterns (SO + TU + M)
- **OpenAI** for GPT-4o-mini API
- **FastAPI** community for excellent framework
- **Celery** project for async task processing

## ğŸ“§ Contact

Name - [MD ALI ARMAGHAN](https://x.com/armaghan78)

Email - aliarmaghan78@gmail.com

Project Link: [https://github.com/aliarmaghan/supportFlow.AI.git](https://github.com/aliarmaghan/supportFlow.AI.git)

---

**â­ Star this repo if you find it helpful!**

Built with â¤ï¸ using OpenAI, FastAPI, and PostgreSQL